{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62122204",
   "metadata": {},
   "source": [
    "# AFF Disease Prediction Using BEHRT - Preprocessing for MLM\n",
    "\n",
    "This notebook demonstrates preprocessing steps for AFF disease prediction using BEHRT, including handling patient information, disease history, and creating training datasets for MLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the disease codes\n",
    "csv_dir = '/path/to/csv/'\n",
    "Dis_codeF = pd.read_csv(csv_dir + \"DS.csv\")\n",
    "\n",
    "# Convert the DataFrame to a pickle file\n",
    "with open('DS.pkl', 'wb') as f:\n",
    "    pickle.dump(Dis_codeF, f)\n",
    "\n",
    "# Load disease history\n",
    "T20 = pd.read_csv(csv_dir + \"T20.csv\")\n",
    "with open('T20.pkl', 'wb') as f:\n",
    "    pickle.dump(T20, f)\n",
    "\n",
    "# Load patient information\n",
    "BFC = pd.read_csv(csv_dir + \"BFC.csv\")\n",
    "with open('BFC.pkl', 'wb') as f:\n",
    "    pickle.dump(BFC, f)\n",
    "\n",
    "# Merge disease history and patient information\n",
    "T20_BFC = pd.merge(T20, BFC, how='left', on='ID')\n",
    "\n",
    "# Add AGE2 column\n",
    "T20_BFC['AGE2'] = T20_BFC['YEAR'].astype('int64') - 2002 + T20_BFC['AGE'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba6da7",
   "metadata": {},
   "source": [
    "## Step 1: Count Disease Occurrences Per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count unique diseases by year and patient\n",
    "year_cnt = T20_BFC[['d', 'ID', 'YEAR', 'AGE']].groupby(['YEAR', 'ID', 'AGE'], as_index=False).agg({\"d\": \"nunique\"})\n",
    "year_cnt = pd.DataFrame(year_cnt).reset_index()\n",
    "\n",
    "# Pivot the data for analysis\n",
    "year_cnt2 = year_cnt.pivot(index=\"ID\", columns=[\"YEAR\"], values=[\"d\", \"AGE\"])\n",
    "year_cnt2 = year_cnt2.apply(lambda x: x.fillna(0), axis=0).reset_index()\n",
    "print(year_cnt2.head())\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_len = max(year_cnt.d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4195968",
   "metadata": {},
   "source": [
    "## Step 2: Padding and Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Padding function\n",
    "def padding(x):\n",
    "    pad = np.zeros(max_len - len(x))\n",
    "    x.extend(pad)\n",
    "    return x\n",
    "\n",
    "# Vocabulary creation function\n",
    "def voc(data):\n",
    "    data_cnt = data.groupby(['YEAR', 'ID']).agg({'d': lambda x: x.tolist()}).reset_index()\n",
    "    data_cnt['d2'] = data_cnt['d']\n",
    "\n",
    "    codes_unique = [item for items in data_cnt['d2'] for item in items]\n",
    "    vocab = dict(zip(set(codes_unique), range(1, len(set(codes_unique)) + 1)))  # 0 for padding\n",
    "    print('Vocabulary size:', len(vocab))\n",
    "    return vocab\n",
    "\n",
    "# Create the vocabulary\n",
    "vocab2 = voc(T20_BFC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68012554",
   "metadata": {},
   "source": [
    "## Step 3: Group Data for MLM and NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group data by patient and year\n",
    "T20_BFC['AGE2'] = T20_BFC['AGE2'].astype(str)\n",
    "T20_BFC['d'] = T20_BFC['d'].astype(str)\n",
    "grouped_diagnoses = T20_BFC.groupby(['ID', 'YEAR'])[['d', 'AGE2']].agg(list).reset_index()\n",
    "\n",
    "# Add 'SEP' to separate sequences\n",
    "grouped_diagnoses['d2'] = grouped_diagnoses['d'].apply(lambda x: x + ['SEP'])\n",
    "grouped_diagnoses['AGE3'] = grouped_diagnoses['AGE2'].apply(lambda x: x + [x[0]])\n",
    "\n",
    "grouped = grouped_diagnoses[['ID', 'AGE3', 'd2']].groupby('ID').apply(\n",
    "    lambda x: pd.Series({'d2': x['d2'].sum(), 'AGE': x['AGE3'].sum()})\n",
    ").reset_index()\n",
    "\n",
    "# Save the grouped data\n",
    "with open('T20_BFC_BEHRT_grouped_df.pkl', 'wb') as f:\n",
    "    pickle.dump(grouped, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a2bd5",
   "metadata": {},
   "source": [
    "## Step 4: Create MLM and NSP Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the grouped data\n",
    "with open('T20_BFC_BEHRT_grouped_df.pkl', 'rb') as f:\n",
    "    grouped_data = pickle.load(f)\n",
    "\n",
    "grouped_data = pd.DataFrame(grouped_data)\n",
    "\n",
    "# Add fold2 column for MLM and NSP splits\n",
    "grouped_data['fold2'] = 0\n",
    "test_index = (grouped_data['ID'].astype(str).str[-1].isin(['1', '3', '5', '7', '9']))\n",
    "grouped_data.loc[test_index, 'fold2'] = 1\n",
    "\n",
    "# Split data for MLM and NSP\n",
    "group_data_mlm1 = grouped_data[grouped_data['fold2'] == 0].reset_index()\n",
    "group_data_mlm2 = grouped_data[grouped_data['fold2'] == 1].reset_index()\n",
    "group_data_nsp1 = grouped_data[grouped_data['fold2'] == 1].reset_index()\n",
    "group_data_nsp2 = grouped_data[grouped_data['fold2'] == 0].reset_index()\n",
    "\n",
    "# Save datasets\n",
    "with open('T20_BFC_BEHRT_group_data_mlm_op1.pkl', 'wb') as f:\n",
    "    pickle.dump(group_data_mlm1, f)\n",
    "\n",
    "with open('T20_BFC_BEHRT_group_data_mlm_op2.pkl', 'wb') as f:\n",
    "    pickle.dump(group_data_mlm2, f)\n",
    "\n",
    "with open('T20_BFC_BEHRT_group_data_nsp_op1.pkl', 'wb') as f:\n",
    "    pickle.dump(group_data_nsp1, f)\n",
    "\n",
    "with open('T20_BFC_BEHRT_group_data_nsp_op2.pkl', 'wb') as f:\n",
    "    pickle.dump(group_data_nsp2, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9aac0",
   "metadata": {},
   "source": [
    "## Step 5: Verify Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verify the splits\n",
    "print(\"MLM Dataset Option 1 Size:\", len(group_data_mlm1))\n",
    "print(\"MLM Dataset Option 2 Size:\", len(group_data_mlm2))\n",
    "print(\"NSP Dataset Option 1 Size:\", len(group_data_nsp1))\n",
    "print(\"NSP Dataset Option 2 Size:\", len(group_data_nsp2))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
