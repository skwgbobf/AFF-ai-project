{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9b20b6",
   "metadata": {},
   "source": [
    "# AFF Disease Prediction Using BEHRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b104e34",
   "metadata": {},
   "source": [
    "This notebook implements AFF disease prediction using BEHRT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43049342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys \n",
    "sys.path.insert(0, '../') \n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from common.common import create_folder\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_pretrained_bert as Bert\n",
    "from model import optimiser\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import roc_auc_score, auc, f1_score, average_precision_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from dataLoader.NextXVisit2 import NextVisit\n",
    "from model.NextXVisit2 import BertForMultiLabelPrediction\n",
    "from common.common import load_obj\n",
    "from model.utils import age_vocab\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d10b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load vocabulary\n",
    "import pickle\n",
    "with open('./vocab2_new.pkl', 'rb') as f:\n",
    "    vocab2_new = pickle.load(f)\n",
    "\n",
    "# Define configurations\n",
    "file_config = {\n",
    "    'vocab': 'vocab2_new',\n",
    "    'train': 'train',\n",
    "    'test': 'test',\n",
    "}\n",
    "\n",
    "optim_config = {\n",
    "    'lr': 1.857576788683168e-05,\n",
    "    'warmup_proportion': 0.14677794038068517,\n",
    "    'weight_decay': 0.005229456209250363\n",
    "}\n",
    "\n",
    "global_params = {\n",
    "    'batch_size': 256,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'device': 'cuda',\n",
    "    'output_dir':'../ndp',\n",
    "    'best_name': 'ndp_best_j_0',\n",
    "    'max_len_seq': 64,\n",
    "    'max_age': 110,\n",
    "    'age_year': False,\n",
    "    'age_symbol': None,\n",
    "    'min_visit': 3\n",
    "}\n",
    "\n",
    "pretrain_model_path = './T20_BFC_MLM_3_op1_v1'\n",
    "\n",
    "# Create word dictionary\n",
    "word_dict = {'PAD': 0, 'CLS': 1, 'SEP': 2, 'MASK': 3, 'UNK' :4}\n",
    "for i, w in enumerate(vocab2_new):\n",
    "   word_dict[w] = i + 4\n",
    "vocab_size = len(word_dict)\n",
    "\n",
    "BertVocab = word_dict\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], symbol=global_params['age_symbol'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model configuration\n",
    "model_config = {\n",
    "    'vocab_size': len(BertVocab.keys()),\n",
    "    'hidden_size': 288,\n",
    "    'seg_vocab_size': 2,\n",
    "    'age_vocab_size': len(ageVocab.keys()),\n",
    "    'max_position_embedding': global_params['max_len_seq'],\n",
    "    'hidden_dropout_prob': 0.1,\n",
    "    'num_hidden_layers': 10,\n",
    "    'num_attention_heads': 12,\n",
    "    'attention_probs_dropout_prob': 0.1,\n",
    "    'intermediate_size': 512,\n",
    "    'hidden_act': 'gelu',\n",
    "    'initializer_range': 0.04,\n",
    "}\n",
    "\n",
    "# Feature configuration\n",
    "feature_dict = {\n",
    "    'word': True,\n",
    "    'seg': True,\n",
    "    'age': True,\n",
    "    'position': True\n",
    "}\n",
    "\n",
    "# Define BertConfig\n",
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings=config.get('max_position_embedding'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.seg_vocab_size = config.get('seg_vocab_size')\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee924957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load datasets\n",
    "with open('../task/d138_5y_onset_Train2_jan2024_aug06_sep26_F.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open('../task/d138_5y_onset_Valid2_jan2024_aug06_sep26_F.pkl', 'rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "\n",
    "with open('../task/d138_5y_onset_Test2_jan2024_aug06_sep26_F.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "# Reset indices\n",
    "train.index = range(len(train))\n",
    "valid.index = range(len(valid))\n",
    "test.index = range(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d378c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DataLoader\n",
    "Dset = NextVisit(token2idx=BertVocab, label2idx=BertVocab, age2idx=ageVocab, dataframe=train, max_len=global_params['max_len_seq'], code='disease_sequenceF', age='age2_sequenceF', label='d138')\n",
    "trainload = DataLoader(dataset=Dset, batch_size=global_params['batch_size'], shuffle=True, num_workers=3)\n",
    "\n",
    "Dset2 = NextVisit(token2idx=BertVocab, label2idx=BertVocab, age2idx=ageVocab, dataframe=test, max_len=global_params['max_len_seq'], code='disease_sequenceF', age='age2_sequenceF', label='d138')\n",
    "testload = DataLoader(dataset=Dset2, batch_size=global_params['batch_size'], shuffle=False, num_workers=3)\n",
    "\n",
    "#Dset = NextVisit(token2idx=BertVocab, label2idx=labelVocab, age2idx=ageVocab, dataframe=train, max_len=global_params['max_len_seq'],code='disease_sequence2', age='age_sequence', label='Diag_d')\n",
    "Dset3 = NextVisit(token2idx=BertVocab, label2idx=labelVocab, age2idx=ageVocab, dataframe=valid, max_len=global_params['max_len_seq'],code='disease_sequenceF', age='age2_sequenceF',label= 'd138') #label= 'd_138') #'Diag_d')\n",
    "# Dset = NextVisit(token2idx=BertVocab, label2idx=labelVocab, age2idx=ageVocab, dataframe=train, max_len=global_params['max_len_seq'],code='disease_sequence_new', age='age2_sequence_new',label='label') #label= 'd_138') #'Diag_d')\n",
    "validload = DataLoader(dataset=Dset3, batch_size=global_params['batch_size'], shuffle=True, num_workers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Model initialization\n",
    "# conf = BertConfig(model_config)\n",
    "# model = BertForMultiLabelPrediction(conf, num_labels=1, feature_dict=feature_dict)\n",
    "# model = model.to(global_params['device'])\n",
    "\n",
    "# # Optimizer\n",
    "# optim = optimiser.adam(params=list(model.named_parameters()), config=optim_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, model):\n",
    "    # load pretrained model and update weights\n",
    "    pretrained_dict = torch.load(path)\n",
    "    model_dict = model.state_dict()\n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "mode = load_model(pretrain_model_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b726ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(global_params['device'])\n",
    "optim = optimiser.adam(params=list(model.named_parameters()), config=optim_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def precision(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(logits)\n",
    "    label, output=label.cpu(), output.detach().cpu()\n",
    "    tempprc= sklearn.metrics.average_precision_score(label.numpy(),output.numpy(), average='samples')\n",
    "    return tempprc, output, label\n",
    "\n",
    "def precision_test(logits, label):\n",
    "    sig = nn.Sigmoid()\n",
    "    output=sig(logits)\n",
    "    tempprc= sklearn.metrics.average_precision_score(label.numpy(),output.numpy(), average='samples')\n",
    "    roc = sklearn.metrics.roc_auc_score(label.numpy(),output.numpy(), average='samples')\n",
    "    return tempprc, roc, output, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a569877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary class\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(e):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt = 0\n",
    "    for step, batch in enumerate(trainload):\n",
    "        cnt +=1\n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, targets = batch\n",
    "        \n",
    "        #targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "        \n",
    "        loss, logits = model(input_ids, age_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets)\n",
    "        \n",
    "        if global_params['gradient_accumulation_steps'] >1:\n",
    "            loss = loss/global_params['gradient_accumulation_steps']\n",
    "        loss.backward()\n",
    "        \n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        if step % 500==0:\n",
    "            prec, a, b = precision(logits, targets)\n",
    "            print(\"epoch: {}\\t| Cnt: {}\\t| Loss: {}\\t| precision: {}\".format(e, cnt,temp_loss/500, prec))\n",
    "            temp_loss = 0\n",
    "        \n",
    "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "def evaluation():\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    tr_loss = 0\n",
    "    for step, batch in enumerate(validload): #validload instead of testload\n",
    "        model.eval()\n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, targets= batch\n",
    "        #targets = torch.tensor(mlb.transform(targets.numpy()), dtype=torch.float32)\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        targets = targets.to(global_params['device'])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss, logits = model(input_ids, age_ids, segment_ids, posi_ids,attention_mask=attMask, labels=targets)\n",
    "        logits = logits.cpu()\n",
    "        targets = targets.cpu()\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        y_label.append(targets)\n",
    "        y.append(logits)\n",
    "\n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "\n",
    "    aps, roc, output, label = precision_test(y, y_label)\n",
    "\n",
    "     # Convert the tensors to numpy arrays for use with sklearn\n",
    "    y_label_np = y_label.detach().numpy()\n",
    "    y_np = y.detach().numpy()\n",
    "\n",
    "    # Compute the ROC curve and ROC area for each class\n",
    "    fpr, tpr, _ = roc_curve(y_label_np, y_np)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return aps, roc, tr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49534285",
   "metadata": {},
   "outputs": [],
   "source": [
    "## without temp_loss in return : sep25\n",
    "##wwwww\n",
    "best_pre = 0.0\n",
    "best_roc =0.0\n",
    "best_loss =0.0\n",
    "eval_auprc_log = []\n",
    "eval_auroc_log = []\n",
    "#train_loss_log = []\n",
    "eval_loss_log = []\n",
    "for e in range(15):\n",
    "    train(e)\n",
    "    aps, roc, test_loss = evaluation()\n",
    "    eval_auprc_log.append(aps)\n",
    "    eval_auroc_log.append(roc)\n",
    "    eval_loss_log.append(test_loss)\n",
    "    \n",
    "    if aps >best_pre:\n",
    "        # Save a trained model\n",
    "        print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        output_model_file = os.path.join(global_params['output_dir'],global_params['best_name'])\n",
    "        create_folder(global_params['output_dir'])\n",
    "\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        best_pre = aps\n",
    "        best_roc = roc\n",
    "        best_loss= test_loss\n",
    "    print('roc : {}'.format(roc), 'aps : {}'.format(aps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ephonc 10\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, roc_curve, confusion_matrix\n",
    "\n",
    "# Load the best model\n",
    "model_path = os.path.join(global_params['output_dir'], \"ndp_best_j_0\")\n",
    "conf = BertConfig(model_config)\n",
    "model = BertForMultiLabelPrediction(conf, num_labels=1, feature_dict=feature_dict)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "# Move the model to the same device as the tensors\n",
    "print(\"Moving model to device...\")\n",
    "model = model.to(global_params['device'])\n",
    "print(\"Model moved to device.\")\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Apply the model to the test data\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "for batch in testload:  # Use the testload DataLoader you created\n",
    "    # Unpack the batch\n",
    "    age_ids, input_ids, posi_ids, segment_ids, attMask, targets = batch\n",
    "\n",
    "    # Move the batch tensors to the same device as the model\n",
    "    age_ids = age_ids.to(global_params['device'])\n",
    "    input_ids = input_ids.to(global_params['device'])\n",
    "    posi_ids = posi_ids.to(global_params['device'])\n",
    "    segment_ids = segment_ids.to(global_params['device'])\n",
    "    attMask = attMask.to(global_params['device'])\n",
    "    targets = targets.to(global_params['device'])\n",
    "\n",
    "    # Compute the model output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, age_ids, segment_ids, posi_ids, attention_mask=attMask)\n",
    "\n",
    "    # Move the model output tensors back to CPU\n",
    "    outputs = outputs.cpu()\n",
    "    targets = targets.cpu()\n",
    "\n",
    "    # Store the predictions and targets\n",
    "    test_predictions.append(outputs)\n",
    "    test_targets.append(targets)\n",
    "\n",
    "# Concatenate all the predictions and targets\n",
    "test_predictions = torch.cat(test_predictions, dim=0)\n",
    "test_targets = torch.cat(test_targets, dim=0)\n",
    "\n",
    "# Compute the metrics\n",
    "auroc = roc_auc_score(test_targets, test_predictions)\n",
    "auprc = average_precision_score(test_targets, test_predictions)\n",
    "f1 = f1_score(test_targets, test_predictions.round())  # Use round to convert predictions to binary\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Metrics for the best model:\")\n",
    "print(f\"  AUROC: {auroc}\")\n",
    "print(f\"  AUPRC: {auprc}\")\n",
    "print(f\"  F1 Score: {f1}\")\n",
    "\n",
    "# Draw the ROC curve\n",
    "fpr, tpr, _ = roc_curve(test_targets, test_predictions)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUROC = {auroc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot the confusion matrix\n",
    "cm = confusion_matrix(test_targets, test_predictions.round())\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()lt.title('ROC Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot the confusion matrix\n",
    "cm = confusion_matrix(test_targets, test_predictions.round())\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
